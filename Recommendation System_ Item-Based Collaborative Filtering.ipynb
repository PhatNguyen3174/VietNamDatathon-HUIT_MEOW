{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1cN44RlIEaB28FTD30qFiHkN3rqcDgcng","timestamp":1643063696491}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"JBESx3d0HdRL"},"source":["# Data processing\n","import pandas as pd\n","import numpy as np\n","import scipy.stats\n","\n","# Visualization\n","import seaborn as sns\n","\n","# Similarity\n","from sklearn.metrics.pairwise import cosine_similarity"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cpB5VrzK9IIn"},"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Change directory\n","import os\n","os.chdir(\"drive/My Drive/contents/recommendation_system\")\n","\n","# Print out the current directory\n","!pwd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H62RNzlYH0Ok"},"source":["# Read in data\n","ratings=pd.read_csv('ml-latest-small/ratings.csv')\n","\n","# Take a look at the data\n","ratings.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LKgfhxylIcdq"},"source":["# Get the dataset information\n","ratings.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mU6QYpBNIm3e"},"source":["# Number of users\n","print('The ratings dataset has', ratings['userId'].nunique(), 'unique users')\n","\n","# Number of movies\n","print('The ratings dataset has', ratings['movieId'].nunique(), 'unique movies')\n","\n","# Number of ratings\n","print('The ratings dataset has', ratings['rating'].nunique(), 'unique ratings')\n","\n","# List of unique ratings\n","print('The unique ratings are', sorted(ratings['rating'].unique()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5MioG60zKXa_"},"source":["# Read in data\n","movies = pd.read_csv('ml-latest-small/movies.csv')\n","\n","# Take a look at the data\n","movies.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SFKBfIl5P8PG"},"source":["# Merge ratings and movies datasets\n","df = pd.merge(ratings, movies, on='movieId', how='inner')\n","\n","# Take a look at the data\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u0EPqtPs1NpB"},"source":["# Aggregate by movie\n","agg_ratings = df.groupby('title').agg(mean_rating = ('rating', 'mean'),\n","                                                number_of_ratings = ('rating', 'count')).reset_index()\n","\n","# Keep the movies with over 100 ratings\n","agg_ratings_GT100 = agg_ratings[agg_ratings['number_of_ratings']>100]\n","\n","# Check the information of the dataframe\n","agg_ratings_GT100.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H6qAvnu2r7YQ"},"source":["# Check popular movies\n","agg_ratings_GT100.sort_values(by='number_of_ratings', ascending=False).head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-aOVhLD8NcO7"},"source":["# Visulization\n","sns.jointplot(x='mean_rating', y='number_of_ratings', data=agg_ratings_GT100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DjBAkBqL1coX"},"source":["# Merge data\n","df_GT100 = pd.merge(df, agg_ratings_GT100[['title']], on='title', how='inner')\n","df_GT100.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c4sOcbQLJkpH"},"source":["# Number of users\n","print('The ratings dataset has', df_GT100['userId'].nunique(), 'unique users')\n","\n","# Number of movies\n","print('The ratings dataset has', df_GT100['movieId'].nunique(), 'unique movies')\n","\n","# Number of ratings\n","print('The ratings dataset has', df_GT100['rating'].nunique(), 'unique ratings')\n","\n","# List of unique ratings\n","print('The unique ratings are', sorted(df_GT100['rating'].unique()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KySPgXj6wRmh"},"source":["# Create user-item matrix\n","matrix = df_GT100.pivot_table(index='title', columns='userId', values='rating')\n","matrix.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Normalize user-item matrix\n","matrix_norm = matrix.subtract(matrix.mean(axis=1), axis = 0)\n","matrix_norm.head()"],"metadata":{"id":"bouLA2wixGWT"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Zo4UEFWJVyt"},"source":["# Item similarity matrix using Pearson correlation\n","item_similarity = matrix_norm.T.corr()\n","item_similarity.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N-eeqclzKm_V"},"source":["# Item similarity matrix using cosine similarity\n","item_similarity_cosine = cosine_similarity(matrix_norm.fillna(0))\n","item_similarity_cosine"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_NLnHDM34R2B"},"source":["# Pick a user ID\n","picked_userid = 1\n","\n","# Pick a movie\n","picked_movie = 'American Pie (1999)'\n","\n","# Movies that the target user has watched\n","picked_userid_watched = pd.DataFrame(matrix_norm[picked_userid].dropna(axis=0, how='all')\\\n","                          .sort_values(ascending=False))\\\n","                          .reset_index()\\\n","                          .rename(columns={1:'rating'})\n","\n","picked_userid_watched.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Similarity score of the movie American Pie with all the other movies\n","picked_movie_similarity_score = item_similarity[[picked_movie]].reset_index().rename(columns={'American Pie (1999)':'similarity_score'})\n","\n","# Rank the similarities between the movies user 1 rated and American Pie.\n","n = 5\n","picked_userid_watched_similarity = pd.merge(left=picked_userid_watched,\n","                                            right=picked_movie_similarity_score,\n","                                            on='title',\n","                                            how='inner')\\\n","                                     .sort_values('similarity_score', ascending=False)[:5]\n","\n","# Take a look at the User 1 watched movies with highest similarity\n","picked_userid_watched_similarity"],"metadata":{"id":"-cyp2p_RtrYD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate the predicted rating using weighted average of similarity scores and the ratings from user 1\n","predicted_rating = round(np.average(picked_userid_watched_similarity['rating'],\n","                                    weights=picked_userid_watched_similarity['similarity_score']), 6)\n","\n","print(f'The predicted rating for {picked_movie} by user {picked_userid} is {predicted_rating}' )"],"metadata":{"id":"peIuk2tEvjXE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Item-based recommendation function\n","def item_based_rec(picked_userid=1, number_of_similar_items=5, number_of_recommendations =3):\n","  import operator\n","  # Movies that the target user has not watched\n","  picked_userid_unwatched = pd.DataFrame(matrix_norm[picked_userid].isna()).reset_index()\n","  picked_userid_unwatched = picked_userid_unwatched[picked_userid_unwatched[1]==True]['title'].values.tolist()\n","\n","  # Movies that the target user has watched\n","  picked_userid_watched = pd.DataFrame(matrix_norm[picked_userid].dropna(axis=0, how='all')\\\n","                            .sort_values(ascending=False))\\\n","                            .reset_index()\\\n","                            .rename(columns={1:'rating'})\n","\n","  # Dictionary to save the unwatched movie and predicted rating pair\n","  rating_prediction ={}\n","\n","  # Loop through unwatched movies\n","  for picked_movie in picked_userid_unwatched:\n","    # Calculate the similarity score of the picked movie iwth other movies\n","    picked_movie_similarity_score = item_similarity[[picked_movie]].reset_index().rename(columns={picked_movie:'similarity_score'})\n","    # Rank the similarities between the picked user watched movie and the picked unwatched movie.\n","    picked_userid_watched_similarity = pd.merge(left=picked_userid_watched,\n","                                                right=picked_movie_similarity_score,\n","                                                on='title',\n","                                                how='inner')\\\n","                                        .sort_values('similarity_score', ascending=False)[:number_of_similar_items]\n","    # Calculate the predicted rating using weighted average of similarity scores and the ratings from user 1\n","    predicted_rating = round(np.average(picked_userid_watched_similarity['rating'],\n","                                        weights=picked_userid_watched_similarity['similarity_score']), 6)\n","    # Save the predicted rating in the dictionary\n","    rating_prediction[picked_movie] = predicted_rating\n","    # Return the top recommended movies\n","  return sorted(rating_prediction.items(), key=operator.itemgetter(1), reverse=True)[:number_of_recommendations]\n","\n","# Get recommendations\n","recommended_movie = item_based_rec(picked_userid=1, number_of_similar_items=5, number_of_recommendations =3)\n","recommended_movie"],"metadata":{"id":"DaXllw2ePo_h"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0xDvkoO9xDIW"},"source":["###### Step 1: Import Python Libraries\n","\n","# Data processing\n","import pandas as pd\n","import numpy as np\n","import scipy.stats\n","\n","# Visualization\n","import seaborn as sns\n","\n","# Similarity\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","\n","###### Step 2: Download And Read In Data\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Change directory\n","import os\n","os.chdir(\"drive/My Drive/contents/recommendation_system\")\n","\n","# Print out the current directory\n","!pwd\n","\n","# Read in data\n","ratings=pd.read_csv('ml-latest-small/ratings.csv')\n","\n","# Take a look at the data\n","ratings.head()\n","\n","# Get the dataset information\n","ratings.info()\n","\n","# Number of users\n","print('The ratings dataset has', ratings['userId'].nunique(), 'unique users')\n","\n","# Number of movies\n","print('The ratings dataset has', ratings['movieId'].nunique(), 'unique movies')\n","\n","# Number of ratings\n","print('The ratings dataset has', ratings['rating'].nunique(), 'unique ratings')\n","\n","# List of unique ratings\n","print('The unique ratings are', sorted(ratings['rating'].unique()))\n","\n","# Read in data\n","movies = pd.read_csv('ml-latest-small/movies.csv')\n","\n","# Take a look at the data\n","movies.head()\n","\n","# Merge ratings and movies datasets\n","df = pd.merge(ratings, movies, on='movieId', how='inner')\n","\n","# Take a look at the data\n","df.head()\n","\n","\n","###### Step 3: Exploratory Data Analysis (EDA)\n","\n","# Aggregate by movie\n","agg_ratings = df.groupby('title').agg(mean_rating = ('rating', 'mean'),\n","                                                number_of_ratings = ('rating', 'count')).reset_index()\n","\n","# Keep the movies with over 100 ratings\n","agg_ratings_GT100 = agg_ratings[agg_ratings['number_of_ratings']>100]\n","agg_ratings_GT100.info()\n","\n","# Check popular movies\n","agg_ratings_GT100.sort_values(by='number_of_ratings', ascending=False).head()\n","\n","# Visulization\n","sns.jointplot(x='mean_rating', y='number_of_ratings', data=agg_ratings_GT100)\n","\n","# Merge data\n","df_GT100 = pd.merge(df, agg_ratings_GT100[['title']], on='title', how='inner')\n","df_GT100.info()\n","\n","# Number of users\n","print('The ratings dataset has', df_GT100['userId'].nunique(), 'unique users')\n","\n","# Number of movies\n","print('The ratings dataset has', df_GT100['movieId'].nunique(), 'unique movies')\n","\n","# Number of ratings\n","print('The ratings dataset has', df_GT100['rating'].nunique(), 'unique ratings')\n","\n","# List of unique ratings\n","print('The unique ratings are', sorted(df_GT100['rating'].unique()))\n","\n","\n","###### Step 4: Create User-Movie Matrix\n","\n","# Create user-item matrix\n","matrix = df_GT100.pivot_table(index='title', columns='userId', values='rating')\n","matrix.head()\n","\n","\n","###### Step 5: Data Normalization\n","\n","# Normalize user-item matrix\n","matrix_norm = matrix.subtract(matrix.mean(axis=1), axis = 0)\n","matrix_norm.head()\n","\n","\n","###### Step 6: Calculate Similarity Score\n","\n","# Item similarity matrix using Pearson correlation\n","item_similarity = matrix_norm.T.corr()\n","item_similarity.head()\n","\n","# Item similarity matrix using cosine similarity\n","item_similarity_cosine = cosine_similarity(matrix_norm.fillna(0))\n","item_similarity_cosine\n","\n","\n","###### Step 7: Predict User's Rating For One Movie\n","\n","# Pick a user ID\n","picked_userid = 1\n","\n","# Pick a movie\n","picked_movie = 'American Pie (1999)'\n","\n","# Movies that the target user has watched\n","picked_userid_watched = pd.DataFrame(matrix_norm[picked_userid].dropna(axis=0, how='all')\\\n","                          .sort_values(ascending=False))\\\n","                          .reset_index()\\\n","                          .rename(columns={1:'rating'})\n","\n","picked_userid_watched.head()\n","\n","# Similarity score of the movie American Pie with all the other movies\n","picked_movie_similarity_score = item_similarity[[picked_movie]].reset_index().rename(columns={'American Pie (1999)':'similarity_score'})\n","\n","# Rank the similarities between the movies user 1 rated and American Pie.\n","n = 5\n","picked_userid_watched_similarity = pd.merge(left=picked_userid_watched,\n","                                            right=picked_movie_similarity_score,\n","                                            on='title',\n","                                            how='inner')\\\n","                                     .sort_values('similarity_score', ascending=False)[:5]\n","\n","# Take a look at the User 1 watched movies with highest similarity\n","picked_userid_watched_similarity\n","\n","# Calculate the predicted rating using weighted average of similarity scores and the ratings from user 1\n","predicted_rating = round(np.average(picked_userid_watched_similarity['rating'],\n","                                    weights=picked_userid_watched_similarity['similarity_score']), 6)\n","\n","print(f'The predicted rating for {picked_movie} by user {picked_userid} is {predicted_rating}' )\n","\n","\n","###### Step 8: Movie Recommendation\n","\n","# Item-based recommendation function\n","def item_based_rec(picked_userid=1, number_of_similar_items=5, number_of_recommendations =3):\n","  import operator\n","  # Movies that the target user has not watched\n","  picked_userid_unwatched = pd.DataFrame(matrix_norm[picked_userid].isna()).reset_index()\n","  picked_userid_unwatched = picked_userid_unwatched[picked_userid_unwatched[1]==True]['title'].values.tolist()\n","\n","  # Movies that the target user has watched\n","  picked_userid_watched = pd.DataFrame(matrix_norm[picked_userid].dropna(axis=0, how='all')\\\n","                            .sort_values(ascending=False))\\\n","                            .reset_index()\\\n","                            .rename(columns={1:'rating'})\n","\n","  # Dictionary to save the unwatched movie and predicted rating pair\n","  rating_prediction ={}\n","\n","  # Loop through unwatched movies\n","  for picked_movie in picked_userid_unwatched:\n","    # Calculate the similarity score of the picked movie iwth other movies\n","    picked_movie_similarity_score = item_similarity[[picked_movie]].reset_index().rename(columns={picked_movie:'similarity_score'})\n","    # Rank the similarities between the picked user watched movie and the picked unwatched movie.\n","    picked_userid_watched_similarity = pd.merge(left=picked_userid_watched,\n","                                                right=picked_movie_similarity_score,\n","                                                on='title',\n","                                                how='inner')\\\n","                                        .sort_values('similarity_score', ascending=False)[:number_of_similar_items]\n","    # Calculate the predicted rating using weighted average of similarity scores and the ratings from user 1\n","    predicted_rating = round(np.average(picked_userid_watched_similarity['rating'],\n","                                        weights=picked_userid_watched_similarity['similarity_score']), 6)\n","    # Save the predicted rating in the dictionary\n","    rating_prediction[picked_movie] = predicted_rating\n","    # Return the top recommended movies\n","  return sorted(rating_prediction.items(), key=operator.itemgetter(1), reverse=True)[:number_of_recommendations]\n","\n","# Get recommendations\n","recommended_movie = item_based_rec(picked_userid=1, number_of_similar_items=5, number_of_recommendations =3)\n","recommended_movie\n"],"execution_count":null,"outputs":[]}]}