{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"dewaamBnrvkJ"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import datetime\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["transactions = pd.read_excel('InventoryAndSale_snapshot_data\\Sales_snapshot_data\\TT T01-2022_split_1.xlsx', dtype={'product_id':str}) # @param {type:\"string\"}\n","transactions.drop(['channel_id', 'cost_price', 'net_price'], inplace=True, axis=1)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 81893 entries, 0 to 81892\n","Data columns (total 9 columns):\n"," #   Column                     Non-Null Count  Dtype \n","---  ------                     --------------  ----- \n"," 0   month                      81893 non-null  int64 \n"," 1   week                       81893 non-null  int64 \n"," 2   site                       81893 non-null  int64 \n"," 3   branch_id                  81893 non-null  int64 \n"," 4   distribution_channel       81893 non-null  object\n"," 5   distribution_channel_code  81893 non-null  object\n"," 6   sold_quantity              81893 non-null  int64 \n"," 7   customer_id                81893 non-null  object\n"," 8   product_id                 81893 non-null  object\n","dtypes: int64(5), object(4)\n","memory usage: 5.6+ MB\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>month</th>\n","      <th>week</th>\n","      <th>site</th>\n","      <th>branch_id</th>\n","      <th>distribution_channel</th>\n","      <th>distribution_channel_code</th>\n","      <th>sold_quantity</th>\n","      <th>customer_id</th>\n","      <th>product_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2022001</td>\n","      <td>202201</td>\n","      <td>1800</td>\n","      <td>1800</td>\n","      <td>Online</td>\n","      <td>ZF2</td>\n","      <td>1</td>\n","      <td>9847d4248</td>\n","      <td>d77fdd34a14845db97837e059b0aca00TRG42</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2022001</td>\n","      <td>202204</td>\n","      <td>1116</td>\n","      <td>1100</td>\n","      <td>Bán lẻ</td>\n","      <td>FP</td>\n","      <td>1</td>\n","      <td>2384aef55</td>\n","      <td>e485c0ab7b9b470cbddb80ea7367e734DEN40</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2022001</td>\n","      <td>202201</td>\n","      <td>1134</td>\n","      <td>1100</td>\n","      <td>Bán lẻ</td>\n","      <td>FP</td>\n","      <td>1</td>\n","      <td>20c3e0442</td>\n","      <td>ac88f78262ee4b589bc93b106b67af1dDEN42</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2022001</td>\n","      <td>202204</td>\n","      <td>1612</td>\n","      <td>1600</td>\n","      <td>Bán lẻ</td>\n","      <td>FP</td>\n","      <td>1</td>\n","      <td>e8b42ff8f</td>\n","      <td>920641c624934c4a8695347737f8f59dDEN35</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2022001</td>\n","      <td>202202</td>\n","      <td>1511</td>\n","      <td>1500</td>\n","      <td>Bán lẻ</td>\n","      <td>FP</td>\n","      <td>1</td>\n","      <td>b8d51499a</td>\n","      <td>6764565f4bb141138af7d9cbf0905d0dHOL33</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     month    week  site  branch_id distribution_channel  \\\n","0  2022001  202201  1800       1800               Online   \n","1  2022001  202204  1116       1100               Bán lẻ   \n","2  2022001  202201  1134       1100               Bán lẻ   \n","3  2022001  202204  1612       1600               Bán lẻ   \n","4  2022001  202202  1511       1500               Bán lẻ   \n","\n","  distribution_channel_code  sold_quantity customer_id  \\\n","0                       ZF2              1   9847d4248   \n","1                        FP              1   2384aef55   \n","2                        FP              1   20c3e0442   \n","3                        FP              1   e8b42ff8f   \n","4                        FP              1   b8d51499a   \n","\n","                              product_id  \n","0  d77fdd34a14845db97837e059b0aca00TRG42  \n","1  e485c0ab7b9b470cbddb80ea7367e734DEN40  \n","2  ac88f78262ee4b589bc93b106b67af1dDEN42  \n","3  920641c624934c4a8695347737f8f59dDEN35  \n","4  6764565f4bb141138af7d9cbf0905d0dHOL33  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["transactions.info()\n","transactions.head()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["start_week = 202201\t\n","# Filter transactions by date\n","\n","transactions = transactions.loc[transactions[\"week\"] >= start_week]\n","\n","# Filter transactions by number of an article has been bought\n","products_bought_count = transactions[['product_id', 'week']].groupby('product_id').count().reset_index().rename(columns={'week': 'count'})\n","most_bought_products = products_bought_count[products_bought_count['count']>10]['product_id'].values\n","transactions = transactions[transactions['product_id'].isin(most_bought_products)]"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["np.random.seed(0)\n","\n","negative_samples = pd.DataFrame({\n","    'product_id': np.random.choice(transactions.product_id.unique(), transactions.shape[0]),\n","    'customer_id': np.random.choice(transactions.customer_id.unique(), transactions.shape[0]),\n","    'sold_quantity': np.zeros(transactions.shape[0])\n","})"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["from sklearn.metrics.pairwise import cosine_similarity\n","\n","\n","class ItemBased_RecSys:\n","    ''' Collaborative filtering using a custom sim(u,u'). '''\n","\n","    def __init__(self, positive_transactions, negative_transactions, num_components=10):\n","        ''' Constructor '''\n","        self.positive_transactions = positive_transactions\n","        self.transactions = pd.concat([positive_transactions, negative_transactions])\n","        self.customers = self.transactions.customer_id.values\n","        self.articles = self.transactions.product_id.values  # Change 'article_id' to 'product_id'\n","        self.sold_quantity = self.transactions.sold_quantity.values  # Change 'bought' to 'sold_quantity'\n","        self.num_components = num_components\n","\n","        self.customer_id2index = {c: i for i, c in enumerate(np.unique(self.customers))}\n","        self.article_id2index = {a: i for i, a in enumerate(np.unique(self.articles))}\n","\n","    def __sdg__(self):\n","        for idx in tqdm(self.training_indices):\n","            # Get the current sample\n","            customer_id = self.customers[idx]\n","            article_id = self.articles[idx]\n","            sold_quantity = self.sold_quantity[idx]  # Change 'bought' to 'sold_quantity'\n","\n","            # Get the index of the user and the article\n","            customer_index = self.customer_id2index[customer_id]\n","            article_index = self.article_id2index[article_id]\n","\n","            # Compute the prediction and the error\n","            prediction = self.predict_single(customer_index, article_index)\n","            error = (sold_quantity - prediction)  # Change 'bought' to 'sold_quantity'\n","\n","            # Update latent factors in terms of the learning rate and the observed error\n","            self.customers_latent_matrix[customer_index] += self.learning_rate * \\\n","                                                            (error * self.articles_latent_matrix[article_index] - \\\n","                                                             self.lmbda * self.customers_latent_matrix[customer_index])\n","            self.articles_latent_matrix[article_index] += self.learning_rate * \\\n","                                                           (error * self.customers_latent_matrix[customer_index] - \\\n","                                                            self.lmbda * self.articles_latent_matrix[article_index])\n","\n","    def fit(self, n_epochs=10, learning_rate=0.001, lmbda=0.1):\n","        ''' Compute the matrix factorization R = P x Q '''\n","        self.learning_rate = learning_rate\n","        self.lmbda = lmbda\n","        n_samples = self.transactions.shape[0]\n","\n","        # Initialize latent matrices\n","        self.customers_latent_matrix = np.random.normal(scale=1., size=(len(np.unique(self.customers)),\n","                                                                       self.num_components))\n","        self.articles_latent_matrix = np.random.normal(scale=1., size=(len(np.unique(self.articles)),\n","                                                                      self.num_components))\n","\n","        for epoch in range(n_epochs):\n","            print('Epoch: {}'.format(epoch))\n","            self.training_indices = np.arange(n_samples)\n","\n","            # Shuffle training samples and follow stochastic gradient descent\n","            np.random.shuffle(self.training_indices)\n","            self.__sdg__()\n","\n","    def predict_single(self, customer_index, article_index):\n","        ''' Make a prediction for a specific user and article '''\n","        prediction = np.dot(self.customers_latent_matrix[customer_index],\n","                           self.articles_latent_matrix[article_index])\n","        prediction = np.clip(prediction, 0, 1)\n","\n","        return prediction\n","\n","    def default_recommendation(self):\n","        ''' Calculate time decaying popularity '''\n","        # Calculate time decaying popularity. This leads to items bought more recently having more weight in the popularity list.\n","        # In simple words, item A bought 5 times on the first day of the train period is inferior than item B bought 4 times on the last day of the train period.\n","        self.positive_transactions['pop_factor'] = self.positive_transactions['week'].apply(lambda x: 202201 - x)\n","        transactions_by_article = self.positive_transactions[['product_id', 'pop_factor']].groupby(\n","            'product_id').sum().reset_index()  # Change 'article_id' to 'product_id'\n","        return transactions_by_article.sort_values(by='pop_factor', ascending=False)[\n","            'product_id'].values[:12]  # Change 'article_id' to 'product_id'\n","\n","    def predict(self, customers):\n","        ''' Make recommendations '''\n","        recommendations = []\n","\n","        # Compute similarity matrix (cosine)\n","        similarity_matrix = cosine_similarity(self.articles_latent_matrix, self.articles_latent_matrix,\n","                                              dense_output=False)\n","\n","        # Convert similarity matrix into a matrix containing the 12 most similar items' index for each item\n","        similarity_matrix = np.argsort(similarity_matrix, axis=1)\n","        similarity_matrix = similarity_matrix[:, -12:]\n","\n","        # Get default recommendation (time decay popularity)\n","        default_recommendation = self.default_recommendation()\n","\n","        # Group articles by user and articles to compute the number of times each article has been bought by each user\n","        transactions_by_customer = self.positive_transactions[['customer_id', 'product_id', 'sold_quantity']].groupby(\n","            ['customer_id', 'product_id']).count().reset_index()  # Change 'article_id' to 'product_id' and 'bought' to 'sold_quantity'\n","        most_bought_article = transactions_by_customer.loc[\n","            transactions_by_customer.groupby('customer_id').sold_quantity.idxmax()][\n","            'product_id'].values  # Change 'article_id' to 'product_id' and 'bought' to 'sold_quantity'\n","\n","        # Make predictions\n","        for customer in tqdm(customers):\n","            try:\n","                rec_aux1 = []\n","                rec_aux2 = []\n","                aux = []\n","\n","                # Retrieve the most bought article by customer\n","                user_most_bought_article_id = most_bought_article[self.customer_id2index[customer]]\n","\n","                # Using the similarity matrix, get the 6 most similar articles\n","                rec_aux1 = self.articles[similarity_matrix[self.article_id2index[user_most_bought_article_id]]]\n","                # Return the half of the default recommendation\n","                rec_aux2 = default_recommendation\n","\n","                # Merge half of both recommendation lists\n","                for rec_idx in range(6):\n","                    aux.append(rec_aux2[rec_idx])\n","                    aux.append(rec_aux1[rec_idx])\n","\n","                recommendations.append(' '.join(aux))\n","            except:\n","                # Return the default recommendation\n","                recommendations.append(' '.join(default_recommendation))\n","\n","        return pd.DataFrame({\n","            'customer_id': customers,\n","            'prediction': recommendations,\n","        })\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0\n"]},{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1\n"]},{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 2\n"]},{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 3\n"]},{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 4\n"]},{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 5\n"]},{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 6\n"]},{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 7\n"]},{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 8\n"]},{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 9\n"]},{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 10\n"]},{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 11\n"]},{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 12\n"]},{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 13\n"]},{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 14\n"]},{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 15\n"]},{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 16\n"]},{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 17\n"]},{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 18\n"]},{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 19\n"]},{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]\n"]}],"source":["rec = ItemBased_RecSys(transactions, negative_samples, num_components=1000)\n","rec.fit(n_epochs=20)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["customers = pd.read_excel('sales_and_inventory_mentor_data\\MasterData\\Distribution Channel.xlsx').customer_id.unique() # @param {type:\"string\"}"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"Found array with 0 sample(s) (shape=(0, 1000)) while a minimum of 1 is required by check_pairwise_arrays.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m recommendations \u001b[38;5;241m=\u001b[39m \u001b[43mrec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcustomers\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[1;32mIn[13], line 85\u001b[0m, in \u001b[0;36mItemBased_RecSys.predict\u001b[1;34m(self, customers)\u001b[0m\n\u001b[0;32m     82\u001b[0m recommendations \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Compute similarity matrix (cosine)\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m similarity_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marticles_latent_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marticles_latent_matrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Convert similarity matrix into a matrix containing the 12 most similar items' index for each item\u001b[39;00m\n\u001b[0;32m     89\u001b[0m similarity_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(similarity_matrix, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n","File \u001b[1;32mc:\\Users\\COHOTECH\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\COHOTECH\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1578\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[0;32m   1544\u001b[0m \n\u001b[0;32m   1545\u001b[0m \u001b[38;5;124;03mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1574\u001b[0m \u001b[38;5;124;03m    Returns the cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[0;32m   1575\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1576\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[1;32m-> 1578\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_pairwise_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1580\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m normalize(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1581\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n","File \u001b[1;32mc:\\Users\\COHOTECH\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:156\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[0;32m    153\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype_float\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m X \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 156\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    166\u001b[0m         X,\n\u001b[0;32m    167\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m    172\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\COHOTECH\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:967\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    965\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[0;32m    966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[1;32m--> 967\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    968\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    969\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    970\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m    971\u001b[0m         )\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    974\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n","\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 1000)) while a minimum of 1 is required by check_pairwise_arrays."]}],"source":["recommendations = rec.predict(customers)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":0}
